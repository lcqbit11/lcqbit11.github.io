# User Profiling through Deep Multimodal Fusion
## 深度多模态用户画像
> 这篇paper是收录在WSDM2018上面的，也是我阅读过的一篇不错的计算用户画像标签的文章，所以就将阅读过程记录下来
> 我几乎将paper文章内容翻译了一遍

### 1.背景介绍
> 很少有工作能将多种数据源或者多模态的数据结合起来用于用户建模的工作中，为了计算更将精准的用户画像，paper中使用深度学习方法来提取和融合不同模态的信息。我们的混合用户画像框架使用了模态之间的一个共享表示，这个共享表示方法是在特征级别整合了三个数据源，在决策级别整合了不同网络的决策结果（而该决策结果是在融合后的数据源上计算得到的），并且在facebook的5K+用户上的试验证明了我们的方法在推理社交媒体用户的年龄、性别、个性化特质时达到了优于其他竞对算法的效果。其中年龄画像的AUC超过了0.9、性别画像的AUC超过了0.95。

> 最近有很多机遇UGC计算用户画像的方法被提出，而大部分的用于推理用户画像技术的创新性工作都是仅仅基于一种类型的数据信息，例如用户的文本类帖子。但是在很多社交媒体平台上，用户会以不同的方式产生内容，例如文本内容（状态更新、博客帖子、推特、评论等）、视觉内容（照片或者视频），同时不同形式的内容之间会相互联系的，创建相关联的内容。一个可以使用用户的所有可用信息的架构能够学习到更准确的用户画像，特别是对于一些平台，每个用户并不是只产生一种类型的信息数据，这（使用多种不同类型的信息）将会非常有用，仅仅给予其中一种类型的信息将不能准确地计算用户画像，例如有些用户只发表更新状态但是从来没有上传过照片，或者有些用户加入社交媒体平台，只是消费知识以及跟好友进行沟通，而不是自己产生文本或者视觉类的内容等。

> 神经网络非常适合于集成多种数据源，因为他们可以通过对训练数据进行非线形结合来解决问题。一个比较早的方法是通过TDNN（时间延迟神经网络）来解决时序多模态数据的问题，一般情况下，神经网络是比较适合于学习高维数据集下的非线性映射关系的，但是由于其训练效率很低下，没有很快成为建模多数据源问题的常用技术，而近些年，GPU的发展解决了训练效率低下的问题，神经网络又重新获得了关注，而DNN也成为了解决模式识别问题包括感知机问题的最佳解决方案，DNN已经在包括手写体字符识别、行人跟踪等很多重要任务上取得了人类水平的优秀效果。DNN的一个主要优势是不再依赖于人工设计特征，而是直接从原始输入中学习特征。

> 这篇paper的主要贡献在于，第一个是提出一个基于DNN的混合架构，它是集成了用户的多种数据源来计算用户画像的，并命名为UDMF（深度多模态融合的用户画像），同时引入了一个stacking机制，其利用了多个目标之间的相互依赖关系来推理用户属性；第二个是在混合级别上，结合了多数据源建模和power-set。UDMF合并了数据源的共享的和非共享的表示，并将他们集成到特征级别和决策级别，我们通过文本数据、视觉数据和关系数据这三种模态的数据源来计算用户画像。第三个是对于社交媒体上的社交关系内容，我们提出了一个叫做Node2Vec的关系嵌入方法，在Node2Vec中，我们通过随机遍历图表来从社交图中提取社交关系特征。而且据我们所知，我们的paper是业界第一篇使用Node2Vec嵌入方式从社交关系上下文中提取社交特征，来推理社交用户的性别、年龄、个性化特征。第四个是，我们经验性的评估基于UDMF架构计算的社交媒体中的用户画像，并使用facebook给出的5k个样本集上将其和当前的最好效果进行对比。

### 2.相关的工作
> 最近，建模异构数据源已经引起了人们的极大兴趣。通过集成两个或者多个数据源来形成统一的描述或者制定更好的决策，这是数据集成框架的主要目标。通过对不同数据源或者模态数据的建模，为传感器网络、机器人、视频、图像处理领域的多媒体任务提供了极大的便利，同时，将例如文本数据、音频数据和视频数据进行整合已经在诸如情感检测、体育视频中的事件监测、依赖传感数据的可穿戴设备等多种任务上获得了极大的成功。paper中，我们为用户画像设计了混合模型，模型包括了在特征层级以及决策层级上组合社交媒体用户的数据

> 已经有很多建模多模态数据源的技术，有关概述，请参考【2】，在这部分，我们首先讨论社交媒体用户画像的相关工作，然后讨论通过深度神经网络建模多种数据源的已有工作。

#### 2.1用户画像
> 现有的大量工作多是根据用户在社交媒体平台上的数字足迹来推理用户的特征，当前的单数据源模型只使用了文本、图像、社交关系中的一种数据。

> （该部分主要讲文本数据源）可以基于用户产生的上下文内容数据例如博客帖子、状态更新等训练机器学习模型，来推理用户的性别、年龄、个性化特征。在过去几年里，用户画像已经获得了很多的关注，研讨会以及例如PAN这样的竞赛聚焦于通过不同的特征和技术来预测用户的年龄和性别、其他的例如预测个性化特征的WCPR这样的共享任务也是今年来的一些尝试。

> （该部分主要讲图像数据源） 除了这些，最近使用深度神经网络从视觉内容中进行年龄和性别的识别已经获得了重要的进展，举个例子，Rothe等人使用卷积神经网络成功地从人脸数据中检测出到用户的年龄和性别。聚焦于这些任务其实有很多比赛，例如LAP 2016的挑战赛是为了从图像中预测出来面部年龄和进行性别分类。但是当前很少有工作是从图像内容中推理用户的个性化特征，Biel and Gatica-Perez基于视觉和音频内容来预测Vloggers的个性化特征，从静态图像例如个人资料图像中来识别个性化特征基本处于未被发掘的领域。最近，在【12】中，面部特征被从用户的资料图像中提取出来用于预测用户的特性，而在本paper中，我们使用了一个类似的方法，该方法是基于Oxford项目的特征，在最终我们的异构用户画像模型中会将其（图像数据）作为我们多个数据源中的一个来使用。

> （该部分主要讲关系数据源）在已有的根据关系数据推理用户特征的工作中，主要关注点是在同性朋友关系、异性朋友关系上【5， 14】、或者用户之间的非直接关系例如看过共同的Facebook 页面的用户之间的关系等，在本paper中，我们使用了一个称为Node2Vec的创新性的嵌入方法，在Node2Vec中，我们使用深度神经网络架构从图（graph）中提取出关系特征。

> 尽管在用户画像领域已经取得了很大的进步，但是使用多模态信息源来计算用户画像的方法仍然是一个未发掘的领域，（其中使用了多模态信息的方法）大多数相关的工作都是在特征级别集成数据源【34】，而跟我们paper中的工作最接近的是wei等人在【29】中的研究，他们在架构中使用集成方法来整合文本数据、头像数据和社交媒介用户的响应模式数据，他们在工作中使用CNN架构借助于神经网络来提取特征，而我们本paper中的工作会有以下几点不同：（1）我们提出了一个可以使用集成方法的混合框架，其就像【29】中所展示；（2）除了预测所有用户的性别特征之外，我们还预测用户的性别和年龄，而Wei等人仅仅预测一些极端用户的个性化特征（其实文章中也可以翻译为人格特征），并在推理的时候去除了其中70%的具有中性人格特点的用户。

#### 2.2深度神经网络的多模态建模
> 在使用深度神经网络来整合多模态数据源上其实已经有了很多的相关研究工作了，我们的框架使用了stacking和power-set和在解决社交媒体用户数据的混合集成问题，相比而言，目前大多数的相关工作要么是只在特征层面组合要么是只在决策层面组合多数据源，根据【15】中的例子，作者在视听语音识别任务中提出了使用深度auto-encoder的方法来学习多模态的特征表达，他们使用了稀疏的限制玻尔兹曼机来预训练深度auto-encoder模型。数据源的混合集成已经被研究的很好了，但是缺乏对数据源的每一种组合方法的优劣性的探索。举个【31】中的例子，作者在视频分类任务中提出了混合深度学习的框架，他们结合了CNN特征和LSTM网络，其中从CNN中提取出来的特征会通过一个规范化的特征层级整合网络而结合起来，而LSTM会用于时间模态中，这样的一个混合架构就自动将LSTM和CNN的特征结合了起来。

> 深度神经网络中的stacking思想已经有了不同的使用方法，举个例子，【30】中，作者在语音识别任务中提出了堆叠瓶颈特征的方法，其中的瓶颈特征，举个例子解释一下：在网络中跟其他隐藏层相比，是由更少的隐藏单元组成的瓶颈层中的激活向量。在【13】中，作者使用stacking方法来堆叠了两个深度神经网络，第一个网络是一个用于特征提取的无监督网络，第二个网络是用于预测任务的有监督网络。而在本paper中，我们在多标签预测中使用了stacking，我们在其中堆叠了为每一个目标label而训练的网络的输出结果，除此之外，类似于【13】，我们也堆叠了两个深度神经网络（也即有监督网络和无监督网络，无监督网络是指Node2Vec），用于在用户画像计算任务中使用创新性的神经网络架构Node2Vec来从关系图中提取特征。最近在特征层面组合特征上有一个相关的工作【32】，其中作者提出了注意力机制的方法来学习交叉特征的权重，作者提出了一个pair-wise交互层来学习嵌入层之后特征交互，而在本paper中，我们提出了在嵌入层上将数据源以power-set的方式进行组合，这考虑到了所有可能的特征组合方式。

**下面开始正式进入本paper的算法部分的内容**

### 3.UDMF: 通过深度多模态融合的方式计算用户画像
> 建模多种数据源的主要目标是集成两种或更多种的数据源/知识源，并且生成一个可以对多数据源（而不仅仅是单个数据源）进行更精准描述的表达形式，而为了设计这样的一个框架，一个主要的考虑点是要在哪个地方对多数据源进行集成的操作，而对此，有两个广为人知的策略，即前置方法（输入部分集成）和后置方法（输出部分集成），图1画出了在深度神经网络架构中的前置方法和后置方法。

![图1][Figure-1]

> 前置方法是一个在特征层面集成多数据源的策略，使用前置方法的一个主要优点是考虑了多数据源以及不同模态之间的相关性，不同模态之间的相关性代表了不同的知识源与另一种知识源之间是如何协同的，数据源之间的这种相关性在数据集成过程中可以提供额外的信息，但是不同的数据源和模态之间并不是必须要互相关联的，因此，除了利用模态之间的依赖性，通过融合独立模态来获得更好的决策结果通常来说是有用的（这意思就是也要在决策层面融合多数据源？）。我们来考虑社交媒体场景下的用户画像，例如用户发的帖子和图片等多模态都可以作为用户与平台之间交互的一种方式，由于缺乏不同数据源的特征之间直接的对应关系，有时候很难在特征层面融合不同的模态。

> 另一种建模多数据源的常用方法是后置方法，其中数据源的交互式发生在决策层面，举个例子，线性权重组合的方式是一种被用到过的最简单的决策层面的后置交互技术，而常用的多数投票集成方法就是这种方法（后置交互方法）的一个特例。

> 在我们的用户画像框架中，在建模多数据源时通过结合前置方法和后置方法，我们能够同时利用到两种方法的优势。我们的混合模型主要有两个特点，第一，它使用了所有的数据源，并通过将数据源组合映射到共享的特征表达来引入了不同模态之间的相关性；第二，数据源的组合也发生在决策层，即我们会结合所有数据源组合的决策结果。另外，在多任务学习的设置中，为了整合目标变量之间的的相关性，我们对于学习过程中的依赖任务迭代地使用了我们的数据集成框架。

> 我们之所以选择深度学习网络来实现我们的用户画像的计算，有以下几个原因。第一，通过使用共享特征表达较容易将模态间的不同数据源结合起来，第二，我们可以将数据源和已经被证明可以提高学习过程效果的非线形函数结合起来，第三，我们能够在原始数据源上使用神经网络并且能够使用非监督学习方法即Node2Vec来提取特征，这在第四部分将会用到。在这部分内容剩下的部分，我们对将数据源和用户画像模型UDMF上的神经元进行连接的架构进行了介绍，为了在UDMF中整合数据源，我们提出了两种机制：stacking和power-set的组合。为了介绍他们，我们从非循环图的多层前馈网络的一般性设置开始介绍，我们以单个输入数据源D开始，其中 i 单元在 h 层上的激活状态计算方式如下：

![公式1][Formula-1]

> 其中，l 层所表示的输出连接着 h 层的输入，j 取遍 l 层上面的所有神经元节点，并且 j 是和 h 层进行连接的，w(hl,ij)表示 l 层上的 j 神经元连接到 h 层上的 i 神经元的权重值，f 是一个激活函数，有可能是一个非线形方程，例如对于输出有可能是一个sigmoid函数，对于隐藏层有可能是一个Relu函数，

> 在 0 层也就是连接输入数据源的层上的神经元 i 的激活状态，按照如下进行定义（当h=0）：

![公式2][Formula-2]

> 其中，wij表示从输入神经元 j 到 0 层上的神经元 i 的连接线上的权重值，Dj 表示输入数据源D上的神经元 j ，而 j 则是可以取输入数据源上的所有值，即第0～|D|个输入值。

> **Stacking**. 我们在本paper中介绍的堆叠机制可以使得UDMF适用于目标变量间具有相关性的多任务学习，本paper所聚焦的用户画像设置中，用户属性之间是互相关联的：举个例子，如果我们知道了用户的性别，那么再去推理用户的年龄将变得更加容易，类似地，因为用户的人口统计学和个性化特征之间是有相关性的，如果预测出了一个用户可以帮助我们去预测另外一个用户的信息。Farnadi等人在【6】中讨论了在三个社交媒体数据集上使用多任务学习来预测用户的人格特征方面的优势。
> 图2中展示了基于同一份数据源堆叠两个目标变量的操作，其中针对两个目标变量训练了两个相似的网络，只不过每一个网络的输入都同时包含输入数据源和另一个目标变量的预测输出。

![图2][Figure-2]

> 假设在训练神经网络过程中有多轮迭代，那么公式2可以被如下的公式3所替代，其中 z 可以取不同的目标变量（例如z in (年龄, 性别)），那么神经网络 0 层上的神经元节点 i 在第 q 轮次的迭代中的激活状态公式为：

![公式3][Formula-3]

> 其中alpha(z) 表示门控变量取值0或者1，如果 z 取值等于自身网络的目标变量，那么alpha(z)=0，否则alpha(z)=1，这种情况下，对于指定网络中的目标变量，会将其他网络中目标变量在第 q-1 轮迭代时的预测值作为改指定网络的输入数据，而在迭代轮次为0时，我们直接用0来初始化所有神经网络目标变量的预测值，因此

![公式4][Formula-4]

> 在每一轮次的迭代中，目标变量预测值的更新都是基于其他目标变量前一轮次的预测值，就像在图2中展示的一样，对于两个目标变量的样本配置来说，对于每一个目标变量，我们都会建立一个类似的架构，在每一轮次的训练迭代中，每个目标变量的预测值都会被堆叠成为其他网络的输入，这种配置可以被简单地推广到更多的网络，即多于两个目标变量的情况，我们也可以每10轮迭代才更新一次目标变量的预测值，而不是每1轮迭代都更新，在第4部分展示的实验中，我们就是每10轮次更新一次目标变量的预测值，这样共迭代了10次，总共有100轮。

> **Power-set combination**.使用DS={D1,D2,,,,Dk}来表示我们想要集成的k种数据源的有限数据集合，需要注意的是k会是一个较小的数字，因为k表示的是每个用户在其上都有数据的数据源的种类数量，在社交媒体中k一般表示2种到至多5种不同的数据源（即文本、视觉、关系数据、时序数据、位置数据），在我们提出的power-set组合方法当中，对于DS数据集中的所有子集，我们通过前置集成方法组合了特征和数据源之间的相关性，然后我们使用ensemble方法将这些子集的预测输出组合成一个后置集成方法，因此UDMF是一个混合数据集成模型，UDMF框架的输入层是由来自于1到k个数据源组成的输入构成的，与输入层进行连接的第一个隐藏层上的神经元节点，有可能会连接到这些数据源任意子集上的输入神经元，准确地说就是，基于k个数据源的集合DS，我们得到了DS的power-set，也就是DS的所有子集集合，如果排除掉空际集合的话，那么DS的合理的子集集合数量为 2^k-1=power(2,k)-1，也就是2的k次方，再减去1，假设k=3表示三种数据源，那么子集集合数量就是power(2,3)-1=7了，很容易理解了（到此处power-set的含义已经比较清晰了，即是指幂次方个的子集集合），对于DS的power-set中每一个非空子集D，我们都会创建一个mini-DNN，即小型DNN网络，对于|D|个数据源在训练轮次 q 时，每一个mini-DNN的其上的 0 层中的神经元节点 i 的激活状态计算如下：

![公式5][Formula-5]

> 其中D属于P(DS)是在mini-DNN中使用到的输入数据源的子集，方程（5）等价于UDMF框架中的方程（2）。

> 作为UDMF框架中数据源的power-set组合的一个例子，我们假设两个可用的数据集A和B，那么DS={A, B}，所以power-set就是 P(DS) {{A}, {B}, {A,B},{}}，因此我们可以创建3个mini-DNN，其中A、B、A和B的结合可以分别成为他们三个各自的输入层。我们在图3中根据这两种数据源和两个目标变量展示了UDMF网络，如图3中所示，我们会为每一个目标变量训练3个mini-DNN网络，因此，总的来说我们训练了6个mini-DNN网络，而为了下一个轮次的迭代训练，在每个迭代轮次上都会将mini-DNN的输出叠加到sister mini-DNN的输入上去。

![图3][Figure-3]

> 如果我们有三种数据源，也就是文本数据、视觉数据和关系数据，以及有7个目标变量（例如在第4部分中p=7），那么我们需要训练 (power(2, 3)-1)*7=49个mini-DNN网络，当我们堆叠目标变量时，我们有一个由于7歌mini-DNN组成的互联网络，而这7个mini-DNN的数据源组合都是来源于数据源P(DS)的power-set，因此，我们有7个DNN模型，他们以不同的方式组合数据源，并且每个DNN模型都包括7个互相连接的mini-DNN，在UDMF中7个DNN模型在决策层面建模多数据源，并以多数投票的方式作为后置整合配置，每一个多目标网络都可以跟其他的分开训练，并行训练每一个power-set组合的多目标网络会大幅减少训练UDMF的时间开销。

### 评估
> 我们使用myPersonality项目数据来训练和测试UDMF框架，myPersonality时facebook在2007看开发的一款受欢迎的应用程序，其中用户可以使用标准的大五人格测试问卷，并允许记录下他们的填写内容以及facebook上的个人资料，此数据集包含的数据类别有人口统计学、朋友关系、facebook上的行为（例如团体的数量、喜欢的页面、教育程度和工作历史）、状态更新资料上的照片以及大五人格分数，但是并不是所有的信息对我们来说都是可用的，我们所选择的用户，母语为英语，提供了年龄、性别、个性化特征、状态更新、喜欢的页面、用户资料照片，为了提高通过照片来描绘资料owner的真实性，我们使用了Oxford人脸检测的API来选择资料照片中只有一个人脸的照片，通过去除掉那些只喜欢少于3个页面的用户，我们最终的数据集包括49372个页面、724928个页面喜欢关系，总共用户数量为5670个。

> 个性化特征通常使用大五人格来进行描述，也就是 外向、令人愉快、责任心、神经质、开放性，该数据集中的个性化分数介于1到5之间，我们根据每一个特征的中间值创建二分类任务，他们的中间值为年龄=23、开放性=4、责任心=3.5、外向性=3.5、令人愉悦性=3.65、神经质性=2.75，通过文本数据（更新的状态）、视觉数据（资料上的照片）、关系数据（喜欢的页面）这三部分数据，我们在facebook用户的年龄、性别和个性化特征上来评估我们提出的用户画像模型。

> 我们系统化地实验了10折交叉验证，因为我们要进行预测的所有任务都是二分类任务（正例 VS 负例），所以我们使用AUC分数来评估结果，AUC是ROC曲线下的面积，ROC是通过对真正例（真实为正样本被预测成了正样本）率against假正例（真实为负样本却被预测成了正样本）率所画出来的曲线，以下小节中的自然语言处理、机器学习、和深度学习技术是通过python中的scikit-learn和keras来实现的。

> 为了能够正确衡量UDMF在集成多个数据源方面的作用，作为我们配置的基础构建模块，我们设计了包含三层神经元的简单DNN，其中第一层是输入层，第二层是一个在每个数据源上都有100个神经元节点作为输入的隐藏层，最后一层是一个sigmoid层用来表示输出结果，对于所有DNN，我们比较的所有网络的隐藏层都使用RELU函数来拟合输入的非线性组合，我们是用Adam作为优化算法，对于本paper中的左右DNN我们训练100个epoch，batch-size设置为128，DNN模型的其他参数适用默认设置，我们将模型的性能和多数基线算法模型进行对比，这些基线算法将训练样本的多数类分配到了测试集合中去，除此之外，我们会这些很好地在特征层面或者决策层面融合了训练数据的多模态组合的baseline进行对比，以显示我们的UDMF方法的优越性能。

#### 4.1 Data Source Embeddings
> 在实践中，数据总是会包括一些噪声，我们只能通过数据清洗和预处理才能得到好的数据表示，在哪种限制条件下使用何种数据处理方法将非常依赖于我们的数据应用类型，在介绍如何融合用户数据之前，我们在这部分将讨论，在社交媒体的用户画像任务中，我们是如何表示数据源的，我们这里定义了三种数据源embeddings表示：来自于文本内容的数据源embeddings、来自于视觉内容的数据源embeddings以及来自于关系内容的数据源embeddings，我们使用上面描述的数据源来获取数据源embeddings。

> **文本数据源embeddings**.为了建立文本数据源的embeddings，我们将每个用户在数据集中更新的状态组合成一篇文档，我们从用户更新的状态中提取出来88个语言查询和单词统计类的特征，相关的特征包括：标准统计（单词统计）、心里活动（例如hate、annoyed等生气的单词的数量）、相关性（未来时态中动词的数量）、涉及职业的单词数量（例如专业、关注点等）、语言维度（例如誓词的数量），如果想要一个完整的概念预览，可以参考下【26】，我们对比了在默认参数下使用LIWC、n-grams(n-1, 2, 3)、基于Twitter数据预训练的300维的GloVe向量、基于英文维基百科数据预训练的300维的fastText向量，使用LIWC特征作为输入层的DNN模型明显好于使用其他特征和embeddings作为输入层类似DNN模型，因此在接下来paper内容中，我们都会使用LIWC文本数据源embeddings，表格1中有Text字样内容代表基于LIWC的DNN模型的效果，由于篇幅的限制，我们将基于其他数据表示的DNN模型的效果从本paper中去除掉了。

> **视觉数据源embeddings**.对于每个用户，我们使用Oxford人脸API从他／她的用户资料的照片中提取出64个面部特征，提取的特征为面部矩形特征，用于捕获出人脸在图像中的位置，其中的面部地标特征，包括指向面部组建中重要位置的27个面部地标点，面部特征还包括年龄、性别、面部毛发、微笑、额头、眼镜类型等，我们对比了将Oxford特征作为输入层模型与从ImageNet的VGG-16及VGG-19模型的最后一层中提取出来的128维激活向量作为输入层模型的效果，使用Oxford特征作为输入层的DNN模型的效果明显好过使用VGG特征作为输入层的模型的效果，特别是对于性别和年龄的预测任务，表格1中有Image字样内容表示的是基于Oxford特征作为输入层的DNN模型的效果，由于篇幅的限制，我们将基于用户画像的其他的embeddings的DNN模型的效果去除掉了。

> **关系数据源embeddings**.为了表达用户所喜欢的页面，我们在关系图上训练了一个叫做Node2Vec的无监督的深度神经网络的方法，Node2Vec是将skip-gram的架构扩展到了网络中，令G=(V, E)为关系图，f表示具有特征的节点的映射函数（也就是 f：V->R(d)），Node2Vec优化下面的目标函数，该函数最大化了 在基于一个节点 u 的特征表示的情况下，观察它的网络领域NS(u)的对数概率，f 如下表示：

![公式6][Formula-6]

> 我们学习了用户到特征的低维空间的映射，这最大化了保留用户和页面的网络邻域的可能性。至此，我们使用主页喜爱关系数据训练了Node2Vec模型，使用从Node2Vec中提取出来的特征，我们不仅给用户展示了他们喜欢的主页（也就是他们的邻域主页），而且可以通过灵活的偏向随机游走程序找到相似的用户来生成NS(u)，而其可以在广度优先采样和深度优先采样中探索邻域，BFS采样源的直接邻居节点，而DFS采样距离源节点越来越远的节点，我们在图上迭代地执行随机Node2Vec游走策略来为每个节点采样得到最近邻的节点，然后通过训练skip-gram架构来为每个节点找到embeddings，我们将embeddings的维度设置为127，在输出的embeddings中，我们选择在我们的域中表示用户的embeddings（作为我们的特征），而忽略掉表示主页的embeddings，使用Node2Vec特征的模型在多个真实网络的多标签分类和链路预测方面表现都优于最先进的技术，据我们所知，我们是第一个借助于Node2Vec 的embeddings技术并使用社交媒体的社交关系数据来计算用户画像的。

> 在一个新的空间中的用户和主页的新的表示，相比于使用喜欢的主页（例如columns）来表示用户（例如 rows）的邻接矩阵来说，能让我们获得额外的知识，为了调研在计算用户画像任务中使用Node2Vec嵌入的模型的效果，我们将使用了Node2Vec特征表示的模型和【11】中的模型进行了效果的对比，在本paper剩下的部分中，我们将后者【11】中的模型称之为 page like 模型 ，在page like模型中，每行表示数据集中的一个用户，每列表示主页，如果用户喜欢该主页，那么矩阵中该条目的值为1，否则为0，在【11】中，Lasso用来预测大五人格特征，但是因为我们的标签是二分类的，所以使用了岭回归模型，它是一个带l2正则化的线性最小二乘分类器，我们将参数值设置成它们在scikit-learn中的默认值。

> 结果展示在图4中，我们将Node2Vec模型（绿色bar显示为Node2Vec模型）和主要的基线模型（灰色bar显示为基线模型）以及page like模型（橘色bar显示为page like模型）进行对比，其中，Node2Vec模型和page like模型都优于基线模型，而Node2Vec模型相比于page like模型在预测所有的label方面都更优秀，特别是Node2Vec模型在预测年龄和性别上产生了一个接近于0.9的AUC值，需要注意的是，我们仅仅使用了3层的简单DNN模型就达到了取得了这样不错的结果，如果我们使用更多的网络层或者使用正则化函数，将有可能进一步提高预测的正确率以及进一步提升结果，但是这些不在本paper的讨论范围内。

![图4][Figure-4]

#### 4.2 Data Source Integration
> 为了在UDMF中集成数据源，我们设计了一个mini-DNN架构，其中有一个网络层为输入神经元准备的，有一个隐藏层是与输入神经元进行全链接的，还有一个输出层是使用sigmoid激活函数对我们的学习任务进行输出的，我们为在stacking过程中进行集成的每一个目标变量建立了一个mini-DNN，在这种方式下，对于数据源的每一个子集，p 个这种类型的mini-DNN在每一个迭代轮次中都会基于其他的 p-1 个mini-DNN 的输出来进行更新，为了融合最终的结果，我们使用多数投票法来决定label值。

> 在用户配置文件的设置中，每一个无标签的用户都会被分配来自于有限的标签集合中的标签，例如在我们这种情况下就是 l={女性、年轻、开放性的、有责任心的、外向的、令人愉快的、神经质的}。我们在图5中展示出了使用UDMF框架的用户画像架构，我们堆叠了7个相似的mini-DNN网络，其中每个网络都是用于训练label集合 l 中的一个目标变量的，每一个网络的参数都可以基于具体每个任务去微调的，可以和其他的网络参数有所不同，但是在paper中，为了简单起见，我们在所有的目标变量上选择了一个具有相同选择的神经网络架构表示，以便互相之间公平的比较结果。

![图5][Figure-5]

> 不同的信息源（用户资料照片、更新的状态数据、喜欢的主页面）都可以为一个准确的用户画像的构建作出贡献，关于文本数据，我们发现年龄较大的用户在更新的状态中（例如，“生日快乐”，“圣诞节快乐”）发表了更多的问候语，神经质用户使用了更多的咒骂词语，有责任心的用户使用了更多的与时间相关的术语，面部毛发的存在与否，例如胡须或者小胡子，是用户性别的最好标志，头部位置是用户外向性的一个不错的标志，用户喜欢的页面也能提供有用的线索，例如“我喜欢成为一个妈妈”是对用户年龄和性别的一个较好的标志。

### 试验结果
> 这部分内容，我们来评估UDMF框架在推理facebook用户的性别、年龄和大五人格上的效果，UDMF包括两个主要的策略：stacking和power-set组合。我们首先来分别测试使用了仅仅堆叠单数据源、堆叠两个数据源、堆叠所有三个数据源（表格1中）的UDMF框架的效果，然后我们测试了根据两个合作三个数据源组合（表格2中展示）的使用了stacking、power-set combination的混合UDMF框架在建模多数据源方面的性能，对于所有的模型，除了被测试的参数之外，其他的参数均使用默认。在年龄预测任务中，使用三个数据源（即是展示在图5中的TIR）来训练mini-DNN模型的学习曲线已经展示在图6中，如图中所示，所有的网络在100个迭代轮次之后就收敛了，我们忽略了其他mini-DNN网络的学习曲线以及由于相似的行为导致的其他特征。

![表1][Table-1]
![表1][Table-1]
![图6][Figure-6]

> **单模态基线**.为了评估UDMF，我们首先在上面展示（方程2）的基本DNN结构下计算仅仅使用单数据源的效果，这些展示在表格1中的第一行部分，有Text、Image、Relation，就像预期的那样，使用从用户资料照片中提取的Oxford 特征来建模图像数据模型，在年龄和性别的预测上都超过了主要的基线模型，但是在大五人格方面这些特征表现的比较差，而使用LIWC特征的文本模型在预测所有label上面均超过了主要的基线模型，使用Node2Vec特征的模型在推理所有特性方面都表现的相当不错。使用单一数据源而表现最好的模型，是使用了基于Node2Vec特征的数据源嵌入的关系模型。

> **多模态基线**.我们将数据源在特征层面和决策层面均进行组合，我们混合了两个数据源和三个数据源的所有组合，在特征层面组合两种数据源的效果展示在了表格1第二部分（即 “Two Sources”）的奇数行上，其中 TI 表示文本和视觉数据源的组合，TR 表示文本和关系数据源的组合，IR 表示视觉和关系数据源的组合，就像预期中的那样，在特征层面整合数据源（也就是 早期整合的方式）相比于表格1第一部分的单一数据源模型的效果更好，组合三种数据源的早期整合方法和后期整合方法的效果比较相近，但是早期整合方法会比后期整合方法（多数投票）的效果稍微好一些，这些结果展示在了表格1最后一部分的奇数行上。


### 总结
> 框架的拆解

> 1.多模态数据如何输入网络

> `需要对原始多模态数据进行预处理，生成embedding向量`
>> - Text: LIWC嵌入,“语言探索与字词计数”，是一种可以对文本内容的词语类别(尤其是心理学类词语)进行量化分析的算法。我们从用户更新的状态中提取出来88个语言查询和单词统计类的特征，相关的特征包括：标准统计（单词统计）、心里活动（例如hate、annoyed等生气的单词的数量）、相关性（未来时态中动词的数量）、涉及职业的单词数量（例如专业、关注点等）、语言维度（例如誓词的数量）；
>> - Image: 使用Oxford项目的面部特征API来提取人脸特征，提取的特征为面部矩形特征，用于捕获出人脸在图像中的位置，其中的面部地标特征，包括指向面部组建中重要位置的27个面部地标点，面部特征还包括年龄、性别、面部毛发、微笑、额头、眼镜类型等；
>> - Relation: Node2Vec,是将skip-gram的架构扩展到了网络中。该方法对比了 page like模型， page like其实就是一个矩阵，每行表示用户，每列表示用户喜欢的主页面，而Node2Vec生成用户关系向量用于模型训练的效果明显好于page like。

> 2.多模态数据在哪里集成
>> - Early approach：在特征层面集成多摸它数据源
>> - Late approach：在决策层面层面集成多摸它数据源

> 3.多模态数据如何集成
>> - Power-set combination：数据源的幂次个子集的组合
>> - Stacking：利用多个目标之间的相互依赖关系来推理用户属性

>[Figure-1]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-1.jpg
>[Figure-2]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-2.jpg
>[Figure-3]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-3.jpg
>[Figure-4]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-4.jpg
>[Figure-5]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-5.jpg
>[Figure-6]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Figure-6.jpg
>[Formula-1]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-1.jpg
>[Formula-2]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-2.jpg
>[Formula-3]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-3.jpg
>[Formula-4]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-4.jpg
>[Formula-5]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-5.jpg
>[Formula-6]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Formula-6.jpg
>[Table-1]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Table-1.jpg
>[Table-2]:/Users/lcq-mac/pycharm_projects/github.image/UDMF/Table-2.jpg
